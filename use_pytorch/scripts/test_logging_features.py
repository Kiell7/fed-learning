#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•è®­ç»ƒæ—¥å¿—åŠŸèƒ½
åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®æ¥æµ‹è¯•å¯è§†åŒ–å’Œæ—¥å¿—åŠŸèƒ½
"""

import os
import sys
import csv
import numpy as np
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)
from utils.visualization import plot_training_progress


def create_test_data(num_rounds=20):
    """
    åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    """
    print(f"ğŸ“Š ç”Ÿæˆ {num_rounds} è½®çš„æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®...")
    
    # æ¨¡æ‹ŸæŸå¤±ï¼šä»é«˜åˆ°ä½é€’å‡ï¼Œå¸¦æœ‰ä¸€äº›æ³¢åŠ¨
    losses = []
    base_loss = 2.5
    for i in range(num_rounds):
        noise = np.random.normal(0, 0.05)
        loss = base_loss * np.exp(-0.05 * i) + noise
        losses.append(max(0.1, loss))
    
    # æ¨¡æ‹Ÿå‡†ç¡®ç‡ï¼šä»ä½åˆ°é«˜é€’å¢ï¼Œå¸¦æœ‰ä¸€äº›æ³¢åŠ¨
    accuracies = []
    for i in range(num_rounds):
        noise = np.random.normal(0, 1)
        acc = 100 * (1 - np.exp(-0.08 * i)) + noise
        accuracies.append(min(99, max(10, acc)))
    
    # æ¨¡æ‹Ÿç¼–ç é•¿åº¦ï¼šä¸‰ä¸ªä¸åŒçš„æ›²çº¿
    all_lengths = []
    for i in range(num_rounds):
        length_1 = 7.0 + np.sin(i * 0.3) * 0.5 + np.random.normal(0, 0.1)
        length_2 = 5.5 + np.cos(i * 0.2) * 0.3 + np.random.normal(0, 0.08)
        length_3 = 10.0 - i * 0.01 + np.random.normal(0, 0.15)
        all_lengths.append([length_1, length_2, length_3])
    
    return losses, accuracies, all_lengths


def test_csv_logging(output_dir, num_rounds=20):
    """
    æµ‹è¯•CSVæ—¥å¿—è®°å½•åŠŸèƒ½
    """
    print("\n" + "="*60)
    print("æµ‹è¯• 1: CSV æ—¥å¿—è®°å½•")
    print("="*60)
    
    losses, accuracies, all_lengths = create_test_data(num_rounds)
    
    # åˆ›å»ºæµ‹è¯•ç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºCSVæ–‡ä»¶
    log_csv_path = os.path.join(output_dir, 'training_log.csv')
    print(f"\nğŸ“ åˆ›å»ºCSVæ—¥å¿—: {log_csv_path}")
    
    with open(log_csv_path, 'w', newline='') as csv_file:
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(['Round', 'Accuracy', 'Loss', 'Length_1', 'Length_2', 'Length_3'])
        
        for i in range(num_rounds):
            csv_writer.writerow([
                i + 1,
                f'{accuracies[i]:.4f}',
                f'{losses[i]:.6f}',
                f'{all_lengths[i][0]:.6f}',
                f'{all_lengths[i][1]:.6f}',
                f'{all_lengths[i][2]:.6f}'
            ])
    
    print(f"âœ… CSVæ–‡ä»¶åˆ›å»ºæˆåŠŸï¼")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œ
    print(f"\nå‰5è¡Œæ•°æ®é¢„è§ˆ:")
    with open(log_csv_path, 'r') as f:
        for i, line in enumerate(f):
            if i < 6:  # æ ‡é¢˜ + 5è¡Œæ•°æ®
                print(f"  {line.strip()}")
    
    return log_csv_path


def test_visualization(output_dir, num_rounds=20):
    """
    æµ‹è¯•å¯è§†åŒ–åŠŸèƒ½
    """
    print("\n" + "="*60)
    print("æµ‹è¯• 2: å¯è§†åŒ–æ›²çº¿ç”Ÿæˆ")
    print("="*60)
    
    losses, accuracies, all_lengths = create_test_data(num_rounds)
    
    # æµ‹è¯•å¯è§†åŒ–å‡½æ•°
    plot_path = os.path.join(output_dir, 'test_training_progress.png')
    print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨: {plot_path}")
    
    plot_training_progress(losses, accuracies, all_lengths, save_path=plot_path)
    
    if os.path.exists(plot_path):
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨ç”ŸæˆæˆåŠŸï¼")
        file_size = os.path.getsize(plot_path) / 1024  # KB
        print(f"   æ–‡ä»¶å¤§å°: {file_size:.2f} KB")
    else:
        print(f"âŒ å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå¤±è´¥ï¼")
    
    return plot_path


def test_checkpoint_format(output_dir):
    """
    æµ‹è¯• checkpoint æ ¼å¼
    """
    print("\n" + "="*60)
    print("æµ‹è¯• 3: Checkpoint æ ¼å¼")
    print("="*60)
    
    import torch
    
    # åˆ›å»ºæ¨¡æ‹Ÿcheckpoint
    checkpoint = {
        'round': 50,
        'model_state_dict': {'layer.weight': torch.randn(10, 5)},
        'optimizer_state_dict': {},
        'accuracy': 75.234,
        'loss': 0.456789,
        'lengths': [7.3174, 5.4738, 10.0]
    }
    
    checkpoint_path = os.path.join(output_dir, 'test_checkpoint.pth')
    print(f"\nğŸ’¾ ä¿å­˜æµ‹è¯•checkpoint: {checkpoint_path}")
    
    torch.save(checkpoint, checkpoint_path)
    
    # è¯»å–å¹¶éªŒè¯
    loaded = torch.load(checkpoint_path)
    print(f"\nâœ… Checkpoint ä¿å­˜å’ŒåŠ è½½æˆåŠŸï¼")
    print(f"\nå†…å®¹:")
    print(f"  è½®æ¬¡: {loaded['round']}")
    print(f"  å‡†ç¡®ç‡: {loaded['accuracy']:.4f}")
    print(f"  æŸå¤±: {loaded['loss']:.6f}")
    print(f"  ç¼–ç é•¿åº¦: {loaded['lengths']}")
    
    return checkpoint_path


def run_all_tests():
    """
    è¿è¡Œæ‰€æœ‰æµ‹è¯•
    """
    print("\n" + "="*70)
    print(" "*20 + "è®­ç»ƒæ—¥å¿—åŠŸèƒ½æµ‹è¯•")
    print("="*70)
    
    # åˆ›å»ºæµ‹è¯•è¾“å‡ºç›®å½•
    test_dir = '/home/student4/njj/fed-learning-feature-dev/use_pytorch/test_output'
    print(f"\nğŸ“ æµ‹è¯•è¾“å‡ºç›®å½•: {test_dir}")
    
    os.makedirs(test_dir, exist_ok=True)
    
    # æµ‹è¯•1: CSVæ—¥å¿—
    csv_path = test_csv_logging(test_dir, num_rounds=20)
    
    # æµ‹è¯•2: å¯è§†åŒ–
    plot_path = test_visualization(test_dir, num_rounds=20)
    
    # æµ‹è¯•3: Checkpointæ ¼å¼
    checkpoint_path = test_checkpoint_format(test_dir)
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“")
    print("="*70)
    print(f"\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  1. CSVæ—¥å¿—: {csv_path}")
    print(f"  2. å¯è§†åŒ–å›¾è¡¨: {plot_path}")
    print(f"  3. Checkpoint: {checkpoint_path}")
    
    print(f"\nğŸ’¡ æç¤º: æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ—¥å¿—:")
    print(f"   python scripts/view_training_log.py {csv_path}")
    print(f"   python scripts/view_training_log.py {csv_path} --report")
    print(f"   python scripts/view_training_log.py {csv_path} --detailed")
    
    print("\n" + "="*70)


if __name__ == '__main__':
    try:
        run_all_tests()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
