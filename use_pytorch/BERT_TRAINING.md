# ä½¿ç”¨ BERT åœ¨ SQuAD æ•°æ®é›†ä¸Šè¿›è¡Œè”é‚¦å­¦ä¹ 

## âœ… å‡†å¤‡å·¥ä½œå·²å®Œæˆ

1. âœ… BERT æ¨¡å‹å·²ä¸‹è½½ (bert-base-uncased, 110M å‚æ•°)
2. âœ… BERTSQuADDataset å·²å®ç° (ä½¿ç”¨ BERT tokenizer)
3. âœ… BERT_QA æ¨¡å‹å·²å®ç° (åŸºäºé¢„è®­ç»ƒ BERT)
4. âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡

## ğŸš€ å¼€å§‹è®­ç»ƒ

### æ–¹æ³•1: ä½¿ç”¨è„šæœ¬ (æ¨è)

```bash
cd /home/student4/njj/fed-learning-feature-dev/use_pytorch
bash run_bert_squad.sh
```

### æ–¹æ³•2: ç›´æ¥å‘½ä»¤

```bash
cd /home/student4/njj/fed-learning-feature-dev/use_pytorch
conda activate fed_learning_njj

python server.py \
    -mn bert \
    -dsn squad \
    -nc 20 \
    -cf 0.5 \
    -E 2 \
    -B 16 \
    -lr 0.00002 \
    -ncomm 100 \
    -sf 10
```

## ğŸ“Š è®­ç»ƒé…ç½®è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `-mn bert` | bert | ä½¿ç”¨ BERT æ¨¡å‹ (110M å‚æ•°) |
| `-dsn squad` | squad | SQuAD 1.1 æ•°æ®é›† |
| `-nc 20` | 20 | 20ä¸ªå®¢æˆ·ç«¯ (æ¯ä¸ªçº¦4380æ ·æœ¬) |
| `-cf 0.5` | 0.5 | æ¯è½®50%å®¢æˆ·ç«¯å‚ä¸ (10ä¸ª) |
| `-E 2` | 2 | æ¯ä¸ªå®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒ2ä¸ªepoch |
| `-B 16` | 16 | æ‰¹å¤§å°16 (BERTæ¨èå°batch) |
| `-lr 0.00002` | 2e-5 | å­¦ä¹ ç‡ (BERTæ ‡å‡†) |
| `-ncomm 100` | 100 | 100è½®é€šä¿¡ |
| `-sf 10` | 10 | æ¯10è½®ä¿å­˜ä¸€æ¬¡ |

### ä¸ºä»€ä¹ˆè¿™æ ·é…ç½®ï¼Ÿ

1. **nc=20, cf=0.5**: 
   - æ¯è½®10ä¸ªå®¢æˆ·ç«¯ Ã— 4380æ ·æœ¬ = 43,800æ ·æœ¬ (50%æ•°æ®è¦†ç›–)
   - æ¯” LSTM çš„ nc=100, cf=0.1 (10%è¦†ç›–) é«˜5å€

2. **E=2, B=16**:
   - BERT å‚æ•°å¤š (110M vs LSTM 7M)
   - å°epoch + å°batch é¿å…è¿‡æ‹Ÿåˆ

3. **lr=2e-5**:
   - BERT é¢„è®­ç»ƒæ¨¡å‹æ ‡å‡†å­¦ä¹ ç‡
   - æ¯” LSTM (1e-3) å°50å€

## ğŸ¯ é¢„æœŸæ•ˆæœ

### LSTM ç»“æœ (å‚è€ƒ)
- 100è½®: EM=2.37%, F1=6.05%
- Loss=0.210

### BERT é¢„æœŸ (æ›´å¥½)
- **å‰20è½®**: Loss å¿«é€Ÿä¸‹é™, EM < 5%
- **20-50è½®**: EM æå‡è‡³ 10-20%
- **50-100è½®**: EM ç¨³å®šåœ¨ 25-40%

**åŸå› **: BERT æœ‰é¢„è®­ç»ƒçŸ¥è¯†ï¼Œç†è§£è¯­ä¹‰æ›´å¥½

## ğŸ“ˆ ç›‘æ§è®­ç»ƒ

è®­ç»ƒä¼šå®æ—¶æ˜¾ç¤º:
```
communicate round 1
Client 0: [BERT] input_idså½¢çŠ¶=torch.Size([16, 384])
start_posèŒƒå›´: 45-256, end_posèŒƒå›´: 47-280
...
round: 1, acc: 3.45, loss: 4.234
EM: 3.45%, F1: 8.21%
```

## ğŸ’¾ ç»“æœä¿å­˜

ç»“æœä¿å­˜åœ¨:
```
./checkpoints/bert_squad_nc20_comm100_<timestamp>/
â”œâ”€â”€ config.json              # è®­ç»ƒé…ç½®
â”œâ”€â”€ checkpoint_round_10.pth  # ç¬¬10è½®checkpoint
â”œâ”€â”€ checkpoint_round_20.pth
â”œâ”€â”€ ...
â”œâ”€â”€ final_model.pth          # æœ€ç»ˆæ¨¡å‹
â””â”€â”€ training_progress.png    # è®­ç»ƒæ›²çº¿
```

## ğŸ”§ è°ƒä¼˜å»ºè®®

å¦‚æœè®­ç»ƒæ•ˆæœä¸ç†æƒ³:

1. **å¢åŠ æ•°æ®è¦†ç›–**:
   ```bash
   -nc 10 -cf 1.0  # æ¯è½®æ‰€æœ‰å®¢æˆ·ç«¯ (100%è¦†ç›–)
   ```

2. **è°ƒæ•´å­¦ä¹ ç‡**:
   ```bash
   -lr 0.00003  # ç¨å¾®æé«˜
   ```

3. **å†»ç»“BERTå±‚** (åªè®­ç»ƒQAå±‚):
   ä¿®æ”¹ `server.py` ç¬¬147è¡Œ:
   ```python
   net = BERT_QA(model_path='./bert_cache/bert-base-uncased-local', freeze_bert=True)
   ```

4. **æ›´å¤šè½®æ¬¡**:
   ```bash
   -ncomm 150  # è®­ç»ƒæ›´ä¹…
   ```

## âš¡ æ€§èƒ½ä¼˜åŒ–

BERT æ¯” LSTM æ…¢å¾ˆå¤š (110M vs 7M å‚æ•°):

- **LSTM**: ~30ç§’/è½®
- **BERT**: ~3-5åˆ†é’Ÿ/è½®

å¦‚æœå¤ªæ…¢:
1. å‡å°‘å®¢æˆ·ç«¯: `-nc 10`
2. å‡å°‘batch: `-B 8`
3. ä½¿ç”¨æ›´å°‘epoch: `-E 1`

## ğŸ†š å¯¹æ¯”å®éªŒ

å»ºè®®åŒæ—¶è·‘ LSTM å’Œ BERT å¯¹æ¯”:

### LSTM (å¿«é€Ÿbaseline)
```bash
python server.py -mn lstm -vs 50000 -dsn squad -nc 20 -cf 0.5 -E 3 -B 64 -lr 0.002 -ncomm 100 -sf 10
```

### BERT (æ›´å¼ºæ€§èƒ½)
```bash
python server.py -mn bert -dsn squad -nc 20 -cf 0.5 -E 2 -B 16 -lr 0.00002 -ncomm 100 -sf 10
```

é¢„æœŸ: BERT çš„ EM åº”è¯¥æ¯” LSTM é«˜ 15-25%
